#!/usr/bin/env python

# Python script to download analysis gear output from Flywheel
#       uses flywheel-sdk to download data based on a user inputted list (CSV)
#
#   created March 23, 2021
#   Modified March 29, 2022
#   amf
#
#   fw_download_gear_output output_dir fw_group_label fw_proj_label gear_name all_subjects [sub_list_file]
# python3 fw_download_analysis_files.py --output_dir data/ --fw_group_label d3b --fw_proj_label Medullo_proc --gear_name captk-brats-pipeline --all_subjects n --sub_list_file sub_list.csv

#out_dir='data/'
#input_fn=[] # "sub_list.csv"
#fw_group_label='d3b'
#fw_proj_label='Medullo_proc'
#gear_name = 'captk-brats-pipeline'

# TO DO:
#   -- consider including the following as optional inputs:
#       include=[''] # file types
#       exclude=[''] # file types
#   -- handle cases w/multiple gear runs in the same session

#  ************** MAIN PROCESSES **************
FLYWHEEL_SDK_REQUEST_TIMEOUT=600
import flywheel
import tarfile
import os
from glob import glob
import shutil
import argparse
import csv
import sys


def main() -> int:
    parser = argparse.ArgumentParser(
        description="A tool to download result files from analysis containers in a Flywheel project.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--output_dir",
        nargs="?",
        required=True,
        help="Directory path to store the downloaded files locally.",
    )
    parser.add_argument(
        "--fw_group_label",
        nargs="?",
        default="d3b",
        choices=["d3b", "corsica"],
        required=True,
        help="Flywheel group that project belongs to.",
    )
    parser.add_argument(
        "--fw_proj_label",
        nargs="?",
        help="Flywheel project to download data from.",
        required=True,
    )
    parser.add_argument(
        "--gear_name",
        nargs="?",
        help="Name of the gear to look for output files from.",
        required=True,
    )
    parser.add_argument(
        "--all_subjects",
        nargs="?",
        choices=["y", "n"],
        help="Whether to download for all subjects in the project, or only look at a subset of subjects.",
        required=True,
    )
    parser.add_argument(
        "--sub_list_file",
        nargs="?",
        help="If only want to download for a subset of subjects, indicate path to CSV file with columns: C-ID (required) and Session (optional).",
    )

    args = parser.parse_args()

    if (args.all_subjects == 'n') and (args.sub_list_file is None):
        parser.error("--all_subjects as 'n' requires --sub_list_file")

    out_dir = args.output_dir
    group_name = args.fw_group_label
    proj_name = args.fw_proj_label
    sub_flag = args.all_subjects
    input_fn = args.sub_list_file
    gear_name = args.gear_name

    # ====== access the flywheel client for your instance ======
    fw = flywheel.Client()

    project = fw.projects.find_first(f'label={proj_name}')

    # ====== set up the subject/session list ======
    # the output of this section will be a list of subject/sessions to look for files to download
    #       this list should be uniform for sub_flag = 'y' or 'n'
    if sub_flag == 'n': # if user doesn't want to include all subjects/sessions
        with open(input_fn, newline='', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            input_sub_list = list(reader)
        if (len(input_sub_list[0]) < 2): # if user only inputted a list of subject ids, find all the corresponding sessions
            all_subs = []
            for subject in all_subs:
                sub_cntr = fw.lookup(os.path.join(group_name, proj_name, subject))
                for session in sub_cntr.sessions.iter():
                    if session.analyses: # if an analysis container exists on the session, include it in the list
                        all_subs.append([session.subject.label, session.label])
        else:
            all_subs = input_sub_list
            all_subs = all_subs[1:] # remove header row
    else:
        all_subs = []
        for session in project.sessions.iter():
            if session.analyses: # if an analysis container exists on the session, include it in the list
                all_subs.append([session.subject.label, session.label])


# ====== loop through subject list & download files for the gear if found ======

    for sub in all_subs:
        sub_label = sub[0]
        ses_label = sub[1]
        print(f'Processing: {sub_label} / {ses_label}')
        ses = fw.lookup(os.path.join(group_name, proj_name, sub_label, ses_label))
        ses = ses.reload()
        analyses = ses.analyses
        if analyses:
            print(f'     {ses_label} has analysis')
            # Check to see if any were generated by our gear
            matches = [asys for asys in analyses if asys.gear_info.get('name') == gear_name]
           # Loop through the analyses and first make sure we only look at successful runs
            matches = [asys for asys in matches if asys.job.get('state')=='complete']
            print(f'     {len(matches)} completed matches. Commencing download')
            # if there is a valid output container, download it
            if len(matches) != 0:
                ind = 0
                if not os.path.isdir(out_dir):
                    os.makedirs(out_dir)
                for match in matches:
                    match = match.reload()
                    output_fn = sub_label+'_'+str(ind)+'.tar'
                    # output_fn = sub_label+'.tar.gz'
                    print(os.path.join(out_dir, output_fn))
                    fw.download_tar(match, os.path.join(out_dir, output_fn))
                    ind += 1

    # unzip tar files & move output files to target sub-dir
    zip_files = glob(os.path.join(out_dir, '*.tar'))
    for file_path in zip_files:
        file = tarfile.open(file_path)
        sub_dir = file_path.strip('.tar')+'/'
        file.extractall(sub_dir)
        file.close()
        out_files = glob(sub_dir+'*/*/*/output/*')
        for out_fn in out_files:
            shutil.move(out_fn, sub_dir)

    # remove tar file & analysis directories
    for file_path in zip_files:
        os.remove(file_path)
        sub_dir = file_path.strip('.tar')+'/'
        # shutil.rmtree(sub_dir+'captk-brats-pipeline 01')

if __name__ == "__main__":
    sys.exit(main())
